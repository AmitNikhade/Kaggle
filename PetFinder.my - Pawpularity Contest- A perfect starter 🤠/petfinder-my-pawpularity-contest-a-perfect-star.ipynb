{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PetFinder.my - Pawpularity Contest- A perfect starter ðŸ¤ \n[Amit Nikhade](http://amitnikhade.com)","metadata":{}},{"cell_type":"markdown","source":"## Flow:\n1) Loading data \n\n2) Pre-processing data\n\n3) Modelling\n\n4) Training\n\n5) Postprocessing\n\n6) Predictions\n\n7) Submission","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# !pip install timm\nimport os\nimport cv2\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n# import timm\nfrom torchvision import models","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:35:14.194169Z","iopub.execute_input":"2021-10-27T06:35:14.194631Z","iopub.status.idle":"2021-10-27T06:35:14.338674Z","shell.execute_reply.started":"2021-10-27T06:35:14.194582Z","shell.execute_reply":"2021-10-27T06:35:14.337925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntest = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:35:14.341427Z","iopub.execute_input":"2021-10-27T06:35:14.341667Z","iopub.status.idle":"2021-10-27T06:35:14.393350Z","shell.execute_reply.started":"2021-10-27T06:35:14.341640Z","shell.execute_reply":"2021-10-27T06:35:14.392656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:35:14.394665Z","iopub.execute_input":"2021-10-27T06:35:14.394931Z","iopub.status.idle":"2021-10-27T06:35:14.419352Z","shell.execute_reply.started":"2021-10-27T06:35:14.394896Z","shell.execute_reply":"2021-10-27T06:35:14.418400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:35:14.420736Z","iopub.execute_input":"2021-10-27T06:35:14.420982Z","iopub.status.idle":"2021-10-27T06:35:14.435379Z","shell.execute_reply.started":"2021-10-27T06:35:14.420949Z","shell.execute_reply":"2021-10-27T06:35:14.434495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:35:14.437732Z","iopub.execute_input":"2021-10-27T06:35:14.438185Z","iopub.status.idle":"2021-10-27T06:35:14.461812Z","shell.execute_reply.started":"2021-10-27T06:35:14.438148Z","shell.execute_reply":"2021-10-27T06:35:14.461125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualizaing sample image","metadata":{}},{"cell_type":"code","source":"#Sample Image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimg = mpimg.imread('../input/petfinder-pawpularity-score/train/0007de18844b0dbbb5e1f607da0606e0.jpg')\nimgplot = plt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:35:14.462912Z","iopub.execute_input":"2021-10-27T06:35:14.463269Z","iopub.status.idle":"2021-10-27T06:35:14.693738Z","shell.execute_reply.started":"2021-10-27T06:35:14.463233Z","shell.execute_reply":"2021-10-27T06:35:14.692992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Augmentation","metadata":{}},{"cell_type":"code","source":"import torchvision.transforms as transforms\ntransform_train = transforms.Compose(\n    [transforms.ToPILImage(),\n     transforms.Resize((224, 224)),\n     transforms.transforms.RandomRotation(20),\n     transforms.ToTensor(),\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n\ntransform_valid = transforms.Compose(\n    [transforms.ToPILImage(),\n     transforms.Resize((224, 224)),\n     transforms.ToTensor(),\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:35:14.695076Z","iopub.execute_input":"2021-10-27T06:35:14.695979Z","iopub.status.idle":"2021-10-27T06:35:14.702737Z","shell.execute_reply.started":"2021-10-27T06:35:14.695941Z","shell.execute_reply":"2021-10-27T06:35:14.702085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\nimport torch.nn as nn\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\nimport timm \nimport torch.optim as optim\n\n\n\nclass Pet_Model(nn.Module):\n    def __init__(self):\n        super(Pet_Model, self).__init__()\n        self.eff = timm.create_model('efficientnet_b0', pretrained=False, in_chans=3)\n        self.rlogit = nn.Linear(1000,128)\n        self.dropout = nn.Dropout(0.1)\n        self.fc1 = nn.Linear(140,64)\n        self.fc2 = nn.Linear(64,1)\n\n   \n    def forward(self, image, dense):\n        x = image\n        x = self.eff(x)  \n        x = self.dropout(x)\n        x = self.rlogit(x)\n        x = torch.cat([x, dense], dim=1)\n        x = self.fc1(x)\n        score = self.fc2(x)\n        \n        return score\n    \nmodel = Pet_Model()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:35:14.705493Z","iopub.execute_input":"2021-10-27T06:35:14.705749Z","iopub.status.idle":"2021-10-27T06:35:20.522329Z","shell.execute_reply.started":"2021-10-27T06:35:14.705719Z","shell.execute_reply":"2021-10-27T06:35:20.521465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Generator","metadata":{}},{"cell_type":"code","source":"class Petfinder_Data(torch.utils.data.Dataset):\n    def __init__(self, data, mode=None):\n        self.data = data\n        self.mode = mode\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        image = cv2.imread('../input/petfinder-pawpularity-score/train/'+row[0]+'.jpg')\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.mode=='train':\n            image = transform_train(image)\n        else:\n            image = transform_valid(image)\n        \n        features = torch.tensor(np.array(row[1:13],dtype=np.float32))\n        label = torch.tensor(np.array(row[-1:],dtype=np.float32))\n        return image, features, label\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:35:21.289148Z","iopub.execute_input":"2021-10-27T06:35:21.289656Z","iopub.status.idle":"2021-10-27T06:35:21.297344Z","shell.execute_reply.started":"2021-10-27T06:35:21.289612Z","shell.execute_reply":"2021-10-27T06:35:21.296419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = data.drop(columns=['Pawpularity'])\ny = data.drop(columns=['Id', 'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:35:24.838954Z","iopub.execute_input":"2021-10-27T06:35:24.839696Z","iopub.status.idle":"2021-10-27T06:35:24.849370Z","shell.execute_reply.started":"2021-10-27T06:35:24.839658Z","shell.execute_reply":"2021-10-27T06:35:24.848434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing / training","metadata":{}},{"cell_type":"code","source":"from torch.autograd import Variable\nfrom torch.optim import lr_scheduler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\nimport gc\n\ntorch.cuda.empty_cache()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\noptimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9,0.999), eps=1e-3, weight_decay=1e-4)\nscheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-6)\ncriterion = nn.MSELoss()\nmodel.to(device)\ne_=[]\nrmse_=[]\nvalid_rmse_=[]\nkfold = StratifiedKFold(n_splits=10)\nfor train_indicies, valid_indicies in kfold.split(X=x ,y=y):\n\n    train_x, valid_x = data.loc[train_indicies], data.loc[valid_indicies]\n    train = Petfinder_Data(train_x,mode='train')\n    valid = Petfinder_Data(valid_x,mode='valid')\n    train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=False, num_workers=0)\n    valid_loader = torch.utils.data.DataLoader(valid, batch_size=64, shuffle=False, num_workers=0)\n    for epoch in range(10):\n        running_loss = 0.0\n        it_num = 0.0\n        error = 0.0\n        dataset_size = 0\n        model.train()\n        for i, t in enumerate(train_loader, 0): \n            \n            image, features, label = t\n            features=Variable(features.cuda().to(torch.float32))\n            image=Variable(image.cuda().to(torch.float32))\n            label=Variable(label.cuda().to(torch.float32))\n        \n            batch_size = image.size(0)\n        \n            outputs = model(image, features)\n            outputs=outputs.to(torch.float32)\n        \n            loss = criterion(outputs, label)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        \n            lr = optimizer.param_groups[0]['lr']\n            running_loss += loss.item()\n            dataset_size += batch_size\n            \n            if i != 0:\n                if running_loss / dataset_size < e_[0] :\n                    if mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False)< rmse_[0]:\n                        e_.clear()\n                        e_.append(running_loss / dataset_size)\n                        rmse_.clear()\n                        rmse_.append(mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False))\n                        print('Epoch:',epoch,'loss: %.3f RMSE: %.3f'%(running_loss / dataset_size,mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False)))\n            else:\n                rmse_.append(mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False))\n                e_.append(running_loss / dataset_size)\n                print('Epoch:',epoch,'loss: %.3f RMSE: %.3f'%(running_loss / dataset_size,mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False)))\n            running_loss = 0.0\n\n        \n        scheduler.step()\n        model.eval()\n        with torch.no_grad():\n            for i, v in enumerate(valid_loader, 0):\n                image, features, label = v\n                features=Variable(features.cuda().to(torch.float32))\n                image=Variable(image.cuda().to(torch.float32))\n                label=Variable(label.cuda().to(torch.float32))\n    \n                outputs = model(image, features)\n                outputs=outputs.to(torch.float32)\n                error = mean_squared_error(label.cpu().detach().numpy(), outputs.detach().cpu().numpy(), squared=False)\n                it_num = i\n                \n                if i!=0:\n                    if error < valid_rmse_[0]:\n                        valid_rmse_.clear()\n                        valid_rmse_.append(error)\n                        print('valid_RMSE:', error )\n                else:\n                    valid_rmse_.append(error)\n                    print('valid_RMSE:', error )\n                        \ntorch.save(model.state_dict(), f'./pet_model.pth')\ndel model\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:36:29.301528Z","iopub.execute_input":"2021-10-27T06:36:29.301963Z","iopub.status.idle":"2021-10-27T12:01:33.261978Z","shell.execute_reply.started":"2021-10-27T06:36:29.301924Z","shell.execute_reply":"2021-10-27T12:01:33.261223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model =  Pet_Model()\nmodel.load_state_dict(torch.load('./pet_model.pth'))\n# model.eval()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:04:16.081973Z","iopub.execute_input":"2021-10-27T12:04:16.082262Z","iopub.status.idle":"2021-10-27T12:04:16.260038Z","shell.execute_reply.started":"2021-10-27T12:04:16.082219Z","shell.execute_reply":"2021-10-27T12:04:16.259340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Post Processing / Predictions","metadata":{}},{"cell_type":"code","source":"class Petfinder_Data(torch.utils.data.Dataset):\n    def __init__(self, data):\n        self.data = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        image = cv2.imread('../input/petfinder-pawpularity-score/test/'+row[0]+'.jpg')\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = transform_valid(image)\n        features = torch.tensor(np.array(row[1:13],dtype=np.float32))\n        return image, features\ntest_df = test.copy()\ntest=Petfinder_Data(test)\ntest_loader = torch.utils.data.DataLoader(test)\nop=[]\nmodel.to(device)\nop.clear()\nfor i, t in enumerate(test_loader, 0): \n            \n        image, features = t\n        features=Variable(features.cuda().to(torch.float32))\n        image=Variable(image.cuda().to(torch.float32))\n\n        \n        outputs = model(image, features)\n        outputs=outputs.to(torch.float32)\n        \n        op.append(outputs.tolist())\n        ","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:04:24.772535Z","iopub.execute_input":"2021-10-27T12:04:24.773239Z","iopub.status.idle":"2021-10-27T12:04:24.997851Z","shell.execute_reply.started":"2021-10-27T12:04:24.773199Z","shell.execute_reply":"2021-10-27T12:04:24.997152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.squeeze(op)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:04:28.551861Z","iopub.execute_input":"2021-10-27T12:04:28.552407Z","iopub.status.idle":"2021-10-27T12:04:28.558658Z","shell.execute_reply.started":"2021-10-27T12:04:28.552367Z","shell.execute_reply":"2021-10-27T12:04:28.557941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Pawpularity'] = predictions","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:04:29.981546Z","iopub.execute_input":"2021-10-27T12:04:29.982253Z","iopub.status.idle":"2021-10-27T12:04:29.987269Z","shell.execute_reply.started":"2021-10-27T12:04:29.982215Z","shell.execute_reply":"2021-10-27T12:04:29.986102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test_df.drop(columns=['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:04:35.581557Z","iopub.execute_input":"2021-10-27T12:04:35.582027Z","iopub.status.idle":"2021-10-27T12:04:35.588152Z","shell.execute_reply.started":"2021-10-27T12:04:35.581986Z","shell.execute_reply":"2021-10-27T12:04:35.586821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performance","metadata":{}},{"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:05:04.702543Z","iopub.execute_input":"2021-10-27T12:05:04.703179Z","iopub.status.idle":"2021-10-27T12:05:04.710808Z","shell.execute_reply.started":"2021-10-27T12:05:04.703137Z","shell.execute_reply":"2021-10-27T12:05:04.709962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}